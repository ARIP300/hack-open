# 62

# J. Ρarviainen, J. Rantala

applications to reach key stakeholders quickly, such as at-risk vulnerable groups (Atique et al. 2020; Tiirinki et al. 2020, p. 660). A pandemic can accelerate the digitalisation of health care, but not all consequences are necessarily predictable or positive from the perspectives of patients and professionals. For instance, if primary healthcare services are increasingly built on chatbots and other digital solutions, the tech industry will increasingly gain in health care and contribute to the ‘corporate privatization of public functions’ (Suarez-Villa 2012, p. 188).

In this article, we take a proactive approach to the potential chatbot breakthrough in health care in relation to the COVID-19 pandemic and consider how the emergence of task-oriented chatbots as partially automated consulting systems can influence clinical practices. Based on findings from recent empirical studies of health chatbots, we approach the topic from the perspective of professional ethics and consider professional–patient relations and the changing positions of these stakeholders on health and medical assessments. Drawing on Aristotle’s account of phronesis, several authors (Conroy et al. 2021; Kaldjian 2014; Montgomery 2006; Oakley and Cocking 2001; Pellegrino and Thomasma 1993; Toon 2014) have developed theoretical accounts of the nature of the practical wisdom needed in medicine to promote good judgement in morally complex situations.

In these ethical discussions, technology use is frequently ignored, technically automated mechanical functions are prioritised over human initiatives, or tools are treated as neutral partners in facilitating human cognitive efforts. So far, there has been scant discussion on how digitalisation, including chatbots, transform medical practices, especially in the context of human capabilities in exercising practical wisdom (Bontemps-Hommen et al. 2019).

We focus on a single chatbot category used in the area of self-care or that precedes contact with a nurse or doctor. These chatbots are variously called dialog agents, conversational agents, interactive agents, virtual agents, virtual humans or virtual assistants (Abd-Alrazaq et al. 2020; Palanica et al. 2019). For instance, in the case of a digital health tool called Buoy or the chatbot platform Omaolo, users enter their symptoms and receive recommendations for care options. Both chatbots have algorithms that calculate input data and become increasingly smarter when people use the respective platforms. The increasing use of bots in health care—and AI in general—can be attributed to, for example, advances in machine learning (ML) and increases in text-based interaction (e.g. messaging, social media, etc.) (Nordheim et al. 2019, p. 5).

Chatbots are based on combining algorithms and data through the use of ML techniques. Their function is thought to be the delivery of new information or a new perspective. However, in general, AI applications such as chatbots function as tools for ensuring that available information in the evidence base is properly considered.

Advocates for the use of chatbots in health care have argued that algorithm-driven systems can free overworked professionals (Topol 2019), reduce the risk of errors (Paredes 2018), provide predictive analysis based on historical and real-time data (Pryce et al. 2018) and increase efficiency in the public sector (Accenture Consulting 2018). They expect that algorithms can make more objective, robust and evidence-based clinical decisions (in terms of diagnosis, prognosis or treatment recommendations) compared to human healthcare providers (HCP) (Morley et al. 2019).

Thus, chatbot platforms seek to automate some aspects of professional decision-making by systematising the traditional analytics of decision-making techniques (Snow 2019). In the long run, algorithmic solutions are expected to optimise the work tasks of medical doctors in terms of diagnostics and replace the routine tasks of nurses through online consultations and digital assistance. Nevertheless, many experts (e.g. Eubanks 2017; Gavaghan et al. 2019; Wachter 2015) have stated that automated systems are not sufficiently reliable to be left to operate independently and that there needs to be a consideration of those factors that are not readily automatable or situations in which a measure of discretion is, for whatever reason, desirable.

In addition, the development of algorithmic systems for health services requires a great deal of human resources, for instance, experts of data analytics whose work also needs to be publicly funded. A complete system also requires a ‘back-up system’ or practices that imply increased costs and the emergence of new problems. The crucial question that policy-makers are faced with is what kind of health services can be automated and translated into machine readable form.

The design principles of most health technologies are based on the idea that technologies should mimic human decision-making capacity. These systems are computer programmes that are ‘programmed to try and mimic a human expert’s decision-making ability’ (Fischer and Lam 2016, p. 23). Thus, their function is to solve complex problems using reasoning methods such as the if-then-else format. In the early days, the problem of these systems was ‘the complexity of mapping out the data in’ the system (Fischer and Lam 2016, p. 23).

Today, advanced AI technologies and various kinds of platforms that house big data (e.g. blockchains) are able to map out and compute in real time most complex data structures. In addition, especially in health care, these systems have been based on theoretical and practical models and methods developed in the field. For example, in the field of psychology, so-called ‘script theory’ provided a formal framework for knowledge (Fischer and Lam 2016). Thus, as a formal model that was already in use, it was relatively easy to turn it into algorithmic form. These expert systems were part of the automated decision-making (ADM) process, that is, a process completely devoid of human involvement, which makes final decisions on the basis of the data it.