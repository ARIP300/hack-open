268 T. Jakobi et al.: The Role of IS in the Conﬂicting Interests Regarding GDPR, Bus Inf Syst Eng 62(3):261–272 (2020)

from the research ﬁeld ,,centralization or decentralization of the IT function’’ could be used.

In a second step, one could aim at transferring knowl- edge from computer-assisted production planning to something that could be called ‘‘computer-assisted legis- lation planning‘‘or ‘‘computer-assisted administration planning‘‘. The process could be to develop – together with accountants as well as specialists for production planning in the manufacturing industry and specialists for data processing in public administration – a prototype to adjust the load of new bureaucratic regulations to enterprises of different sectors. This algorithm should be based on empirical estimations of the person-hours in ﬁrms of various industries and size. Then the so-called capacity proﬁle can be calculated by adding the capacity needs of different regulations over the time axis. Depending on the results in terms of ‘‘summits’’ and ‘‘valleys‘‘, the European Com- mission would plan its own activities, e.g. sessions in the EU-Parliament, and postpone or bring forward the publication and effective date of laws and regulations, whereby the restrictions of the Commission and of the ﬁrms should be considered.

# 5 Information Systems and the General Data Protection Regulation – A Consumer Protection Perspective

Ayten O¨ksu¨z – Consumer Association of North Rhine- Westphalia (Verbraucherzentrale Nordrhein-Westfalen)

From the perspective of consumer protection, the General Data Protection Regulation (GDPR; Directive (EU) 2016/679) is a step in the right direction which updates our data legislation. This is why the consumer association of North Rhine-Westphalia welcomes the GDPR. The regu- lation entails several new principles that aim to empower individuals in gaining more control over their data in a world of growing technological complexities.

# 5.1 Why is This So Important?

Technologization and digitization are increasingly affect- ing all areas of life. We shop online, network on social media, use wearables and ﬁtness trackers to keep an eye on our activities and health, and turn the lights on or off with the help of smart speakers. All these new technologies and services can be seen as signiﬁcant advances which are creating opportunities for people such as simpliﬁcation of daily life and more convenience.

A side-effect is the great amount of data produced through the use of these numerous smart devices and ser- vices. With the help of big data analytics, large volume of data can be examined to bring to light information such as unknown correlations or hidden patterns. On the one hand, this information can be used in a positive way. The application of big data in healthcare, for example, can save life as analyzing speciﬁc health data of a population has the potential to prevent epidemics or to cure diseases. On the downside, in many cases, this data is collected and examined by companies, which do not always act transparently. Parts of the data may seem harmless enough on their own. However, most of the consumer data allows companies to draw conclusions about, e.g., personal preferences, lifestyle habits, religious confessions or diseases, which can also have negative consequences for consumers such as unwanted personalized ads, proﬁling or discrimination (e.g., in terms of insurance). This is why big data also brings along great privacy concerns. Merging and linking user data that was collected over a long period of time and across distinct devices, products or services even intensiﬁes these privacy concerns. As digitization is progressing steadily, data is being collected at an incredible rate, and thus consumers are unable to keep track of which and by whom personal data relating to them is stored and ana- lyzed. A recently published report of Amnesty Interna- tional even concludes that the business model of Google and Facebook threatens human rights (Amnesty Interna- tional 2019). In this context, the non-governmental orga- nization warns against – what they call – the ‘‘omnipresent surveillance of billions of people’’.

Therefore, it is necessary to increase the attention everyone pays to data and to reduce bad practice and the bad players by regulating how data is being used in a reasonable, legal and ethical way. This applies to the per- son who decides on the business model behind an offered service or product as well as to the person who develops the tools, technologies, and algorithms capturing and ana- lyzing data about their users. The GDPR opens up new possibilities to deal with these emerging challenges by making it easier to demand greater transparency and accountability from those who collect and use data. It also provides consumers with more control over their data. For example, requirements for the comprehensibility of privacy policies have increased and information about how and by whom data is collected and used has to be properly dis- closed to consumers. Companies that violate the principles of GDPR face higher monetary penalties so that also big players in the market, which do not act in accordance to data protection law yet, are now forced to change their behavior. According to the ‘‘privacy by default’’ obliga- tion, which is one of the key requirements of the GDPR, data controllers must implement appropriate technical and organizational measures ensuring that only such personal data is collected that is necessary for the speciﬁc purpose mentioned. Thus, the minimum amount of personal data