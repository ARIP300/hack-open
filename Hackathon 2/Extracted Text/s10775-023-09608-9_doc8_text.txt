# International Journal for Educational and Vocational Guidance

using the following cutoffs: r &lt; 0.30, spurious; r &lt; 0.30, weak; r &lt; 0.50, moderate; otherwise, strong (Cohen, 1988).

Multiple linear regressions were implemented to identify the effect of each independent variable controlling for the effect of other independent variables. Four regression models considered MME’s factors as dependent variables and the additional measures’ factors as independent variables. As we wanted to identify the most predictive features among the independent variables, a sequential method was selected rather than the traditional method enter. Thus, regression models were specified by the method forward, which first enters all independent variables in the model and then gradually removes those with nonsignificant regression coefficients (α = 0.05). The method forward is preferred over other sequential methods (such as stepwise) because it avoids the elimination of variables that actually contributes to the prediction of the dependent variable due to the partial correlations between independent variables (Field, 2013).

To ensure the validity of the regression models, several assumptions were verified. The relationships between standardized residuals and predicted values were plotted to assess the residuals’ normality and homoscedasticity (Hair et al., 1998). In addition to the graphic representation, the residuals’ normality and homoscedasticity were assessed by the Shapiro–Wilks test and the Breusch–Pagan test, respectively. The autocorrelations between residuals were assessed by the Durbin–Watson test, with values close to 2.0 being expected (Field, 2013). Multicollinearity was tested by correlation coefficients, tolerance, and variance inflation factor, with low tolerance, high correlations, and high variance inflation factor suggesting high multicollinearity (Hair et al., 1998). Potential atypical and influential observations were identified by Mahalanobis distance and Cook distance, respectively. Bootstrapping correction (500 resampling; 95% CI BCa) was used to adjust potential violations of assumptions and provide more reliable confidence intervals (Haukoos & Lewis, 2005). The regressions were all implemented in R (R Core Team, 2022) using the packages car 3.0-13 (Fox et al., 2012), rstatix 0.7.0 (Kassambara, 2021), and olsrr 0.5.3 (Hebbali & Hebbali, 2017).

# Results

Before implementing the CFA, the frequency of answers across the five response categories in each item were examined. The first response category was answered by a reduced number of participants (n &lt; 19) with two items having no answers at all, and only four items having more than ten answers. Considering that WLSMV is not allowed when response categories are not filled in, the two first response categories were collapsed.

Three models were tested by CFA: the four-factor solution with four correlated factors (M1), the four-factor solution with the four factors loading onto a